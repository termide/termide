# Phase 2: Diagnosis (Parallel Analysis)

**Goal**: Identify all code quality issues, architectural problems, and refactoring opportunities using parallel specialized analyzers.

**Duration**: ~10-20 minutes (parallelized)

**Parallelization**: This phase launches 3 independent analyzers concurrently, then runs DRY analyzer with their context.

## Parallel Execution Strategy

This phase uses **parallel execution** to speed up analysis:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PARALLEL BLOCK 1 (3 concurrent analyzers)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ SOLID Checker  â”‚  â”‚ Performance      â”‚         â”‚
â”‚  â”‚ (Architecture) â”‚  â”‚ Auditor          â”‚  â”Œâ”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                â”‚  â”‚ (Speed & Memory) â”‚  â”‚Dead â”‚â”‚
â”‚  â”‚ ~5-8 min       â”‚  â”‚ ~4-6 min         â”‚  â”‚Code â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                               ~3minâ”‚â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SEQUENTIAL BLOCK (uses results from parallel)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ DRY Analyzer                        â”‚            â”‚
â”‚  â”‚ (Uses SOLID context for better     â”‚            â”‚
â”‚  â”‚  abstraction suggestions)           â”‚            â”‚
â”‚  â”‚ ~4-5 min                            â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
               Consolidate Results
```

**Total time**: ~12-15 minutes (vs ~20-25 minutes sequential)
**Speedup**: ~40-50% faster

## Step-by-Step Process

### Step 2.1: Launch Parallel Analyzers

**IMPORTANT**: These 3 analyzers are INDEPENDENT and should execute CONCURRENTLY.

#### Analyzer 1: SOLID Principles Checker (PARALLEL)

**Task**: Analyze architectural quality against SOLID principles

**Scope**: All public structs, traits, implementations

**Analyzer location**: `../analyzers/solid-checker.md`

**Expected output**: JSON with SOLID violations

**Invocation**:
```
Use Task tool to spawn subagent with ../analyzers/solid-checker.md prompt.
Pass context: Project path, list of main modules from Phase 1.
```

**What it analyzes**:
- Single Responsibility Principle violations
- Open/Closed Principle violations
- Liskov Substitution Principle violations
- Interface Segregation Principle violations
- Dependency Inversion Principle violations

**Example findings**:
```json
{
  "total_violations": 42,
  "by_principle": {"SRP": 15, "OCP": 8, "LSP": 3, "ISP": 12, "DIP": 4},
  "violations": [...]
}
```

---

#### Analyzer 2: Performance Auditor (PARALLEL)

**Task**: Find performance bottlenecks and inefficiencies

**Scope**: Entire codebase, focus on hot paths identified in Phase 1

**Analyzer location**: `../analyzers/performance-auditor.md`

**Expected output**: JSON with performance issues

**Invocation**:
```
Use Task tool to spawn subagent with ../analyzers/performance-auditor.md prompt.
Pass context: Largest files from Phase 1, event handlers, loops.
```

**What it analyzes**:
- Unnecessary allocations (clone, to_string, Box::new)
- Algorithmic inefficiency (nested loops, O(nÂ²) patterns)
- Suboptimal collection usage
- Inefficient string operations
- Premature optimization

**Example findings**:
```json
{
  "total_issues": 38,
  "by_impact": {"critical": 3, "high": 10, "medium": 15, "low": 10},
  "issues": [...]
}
```

---

#### Analyzer 3: Dead Code Finder (PARALLEL)

**Task**: Identify unused, unreachable, and orphaned code

**Scope**: Complete codebase including tests

**Analyzer location**: `../analyzers/dead-code-finder.md`

**Expected output**: JSON with dead code items

**Invocation**:
```
Use Task tool to spawn subagent with ../analyzers/dead-code-finder.md prompt.
Pass context: cargo check/clippy warnings from Phase 1.
```

**What it analyzes**:
- Unused imports
- Unused functions (private and public)
- Unused variables and parameters
- Unused types (structs, enums, type aliases)
- Unused constants and statics
- Unreachable code
- Orphaned test code

**Example findings**:
```json
{
  "total_dead_code_items": 45,
  "by_category": {"unused_imports": 12, "unused_functions": 8, ...},
  "total_lines_removable": 342,
  "items": [...]
}
```

---

### Step 2.2: Wait for Parallel Analyzers to Complete

**Display progress to user**:
```
ğŸ”„ PARALLEL ANALYSIS IN PROGRESS

   [âœ“] SOLID Checker          - Complete (42 violations found)
   [âœ“] Performance Auditor    - Complete (38 issues found)
   [âœ“] Dead Code Finder       - Complete (45 items found)

â±ï¸  Total time: 8 minutes (vs 18 minutes sequential)
ğŸ“Š Issues detected: 125 total

Proceeding to DRY analysis...
```

---

### Step 2.3: Run DRY Analyzer (SEQUENTIAL)

**Why sequential?** DRY analyzer benefits from knowing SOLID violations to suggest better abstractions.

**Task**: Find code duplication and abstraction opportunities

**Scope**: Entire codebase, with special focus on:
- Modules flagged for SRP violations (likely have duplication)
- Files with OCP violations (repeated match statements)
- Areas with similar performance patterns

**Analyzer location**: `../analyzers/dry-analyzer.md`

**Expected output**: JSON with duplication findings

**Invocation**:
```
Use Task tool to spawn subagent with ../analyzers/dry-analyzer.md prompt.
Pass context:
- SOLID violation locations (from Analyzer 1)
- Large files from Phase 1
- Repeated patterns from Performance Auditor
```

**What it analyzes**:
- Exact code duplication
- Structural duplication (similar functions)
- Similar match patterns
- Repeated error handling
- Duplicated trait implementations
- Configuration/constants duplication
- Test code duplication

**Also identifies**: KISS principle violations (over-abstraction)

**Example findings**:
```json
{
  "total_duplications": 23,
  "by_type": {"exact_duplication": 8, "structural_duplication": 7, ...},
  "potential_loc_reduction": 320,
  "issues": [...]
}
```

---

### Step 2.4: Consolidate All Results

**Combine findings from all 4 analyzers**:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         PHASE 2: DIAGNOSIS - RESULTS                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š OVERALL SUMMARY

Total Issues Found: 148
â”œâ”€ SOLID violations: 42 (Architecture)
â”œâ”€ Performance issues: 38 (Speed & Memory)
â”œâ”€ Dead code items: 45 (Maintainability)
â””â”€ DRY violations: 23 (Duplication)

ğŸ”¥ CRITICAL ISSUES: 12
âš ï¸  HIGH PRIORITY: 34
ğŸ“ MEDIUM PRIORITY: 58
â„¹ï¸  LOW PRIORITY: 44
```

**Cross-reference findings**:
- Match dead code locations with SOLID violations (often related)
- Link performance issues to DRY violations (duplicated inefficient code)
- Identify modules with multiple problem types (refactoring priorities)

**Create issue matrix**:
```
MODULE HEATMAP (issues per module):

src/panels/file_manager.rs:
  â”œâ”€ SOLID: 8 violations (SRP: 3, ISP: 5)
  â”œâ”€ Performance: 5 issues (2 critical, 3 high)
  â”œâ”€ Dead code: 7 items
  â””â”€ DRY: 4 duplications
  TOTAL: 24 issues âš ï¸  HIGH REFACTORING PRIORITY

src/editor/buffer.rs:
  â”œâ”€ SOLID: 3 violations (SRP: 2, DIP: 1)
  â”œâ”€ Performance: 12 issues (1 critical, 8 high)
  â”œâ”€ Dead code: 2 items
  â””â”€ DRY: 1 duplication
  TOTAL: 18 issues âš ï¸  PERFORMANCE CRITICAL

src/i18n/:
  â”œâ”€ SOLID: 1 violation
  â”œâ”€ Performance: 0 issues
  â”œâ”€ Dead code: 3 items
  â””â”€ DRY: 9 duplications (mostly translation helpers)
  TOTAL: 13 issues ğŸ“ MEDIUM PRIORITY
```

### Step 2.5: Generate Unified Diagnosis Report

**Create comprehensive JSON**:
```json
{
  "diagnosis_summary": {
    "total_issues": 148,
    "by_severity": {
      "critical": 12,
      "high": 34,
      "medium": 58,
      "low": 44
    },
    "by_category": {
      "architecture": 42,
      "performance": 38,
      "dead_code": 45,
      "duplication": 23
    },
    "estimated_refactoring_effort": "3-5 days for critical+high, 2-3 days for medium"
  },
  "hotspot_modules": [
    {
      "path": "src/panels/file_manager.rs",
      "total_issues": 24,
      "priority": "high",
      "reason": "Multiple SOLID violations + performance issues"
    },
    {
      "path": "src/editor/buffer.rs",
      "total_issues": 18,
      "priority": "critical",
      "reason": "Performance-critical code with significant issues"
    }
  ],
  "analyzer_results": {
    "solid": { ... },
    "performance": { ... },
    "dead_code": { ... },
    "dry": { ... }
  }
}
```

## Phase 2 Output

Present consolidated findings to user:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         PHASE 2: DIAGNOSIS - COMPLETE âœ“                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š ANALYSIS COMPLETE

â±ï¸  Time: 12 minutes (40% faster via parallelization)
ğŸ” Analyzed: 14,890 lines across 32 files
ğŸ¯ Issues found: 148 total

BREAKDOWN BY SEVERITY:
ğŸ”¥ 12 Critical  - Must fix before release
âš ï¸  34 High     - Should fix soon
ğŸ“ 58 Medium    - Good to address
â„¹ï¸  44 Low      - Nice to have

TOP REFACTORING PRIORITIES:
1. src/panels/file_manager.rs (24 issues)
2. src/editor/buffer.rs (18 issues - performance critical!)
3. src/terminal.rs (15 issues)

QUICK WINS (low effort, high impact):
- Remove 45 dead code items (saves 342 LOC)
- Fix 12 unused imports (immediate cleanup)
- Extract 8 duplicated functions (DRY improvements)

ğŸ¯ NEXT PHASE: Assessment (Scoring & Prioritization)
   Will generate project score and ask for your priorities.

Ready to proceed? (automatically continuing...)
```

## Tools Used

- **Task**: Launch parallel subagent analyzers
- **Bash**: Coordinate execution, track progress
- **Read**: Access analyzer results
- **Grep**: Cross-reference findings

## Success Criteria

- [x] All 4 analyzers completed successfully
- [x] Results consolidated into unified report
- [x] Module heatmap generated
- [x] Quick wins identified
- [x] Refactoring priorities established
- [x] Estimated effort calculated

## State to Carry Forward

Store for Phase 3 (Assessment):
- Complete analyzer JSON outputs
- Module heatmap with issue counts
- Quick wins list
- Hotspot modules ranking
- Cross-references between issue types

---

**Proceed to Phase 3: Assessment**
